{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознование текста из микрофона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install portaudio19-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in ./environment/lib/python3.6/site-packages\n",
      "Requirement already satisfied: PyAudio in ./environment/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "!environment/bin/pip install SpeechRecognition\n",
    "!environment/bin/pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.listen??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as micro:\n",
    "    print(1)\n",
    "    audio = recognizer.listen(micro)\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/microphone-results.wav', \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speak speak speak speak speak speak'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.recognize_google(audio, language='en-EN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознование текста из аудиофайла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.AudioFile('data/microphone-results.wav') as source:\n",
    "    audio1 = recognizer.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a sound detection chick 111 detection check'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.recognize_google(audio1, language='en-EN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./py3_env/lib/python3.6/site-packages\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: regex==2018.01.10 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: ujson>=1.35 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./py3_env/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in ./py3_env/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in ./py3_env/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in ./py3_env/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in ./py3_env/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in ./py3_env/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in ./py3_env/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in ./py3_env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./py3_env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./py3_env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./py3_env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: toolz>=0.8.0 in ./py3_env/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy)\n"
     ]
    }
   ],
   "source": [
    "!py3_env/bin/pip install spacy\n",
    "!py3_env/bin/pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.load('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'sound', 'detection', 'chick', '111', 'detection', 'check']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = recognizer.recognize_google(audio, language='en-EN')\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./environment/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: six in ./environment/lib/python3.6/site-packages (from nltk)\r\n",
      "Requirement already satisfied: singledispatch in ./environment/lib/python3.6/site-packages (from nltk)\r\n"
     ]
    }
   ],
   "source": [
    "!environment/bin/pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/anton-\n",
      "[nltk_data]     taleckij/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'их'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemma(\"их\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this\n",
      "be is\n",
      "a a\n",
      "sound sound\n",
      "detection detection\n",
      "chick chick\n",
      "111 111\n",
      "detection detection\n",
      "check check\n"
     ]
    }
   ],
   "source": [
    "for token in tokenize(text):\n",
    "    print(get_lemma(token), get_lemma2(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anton-\n",
      "[nltk_data]     taleckij/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "# en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "en_stop = set(nltk.corpus.stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['со', 'при', 'чтобы', 'может', 'без']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_stop)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    return [get_lemma(token) for token in tokens \n",
    "            if len(token) > 4 and token not in en_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sound', 'detection', 'chick', 'detection', 'check']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = [prepare_text_for_lda(text)]\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./py3_env/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy>=0.18.1 in ./py3_env/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in ./py3_env/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./py3_env/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in ./py3_env/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: boto3 in ./py3_env/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: boto>=2.32 in ./py3_env/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: bz2file in ./py3_env/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: requests in ./py3_env/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in ./py3_env/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in ./py3_env/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.102 in ./py3_env/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in ./py3_env/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./py3_env/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./py3_env/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./py3_env/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in ./py3_env/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.102->boto3->smart-open>=1.7.0->gensim)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in ./py3_env/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.102->boto3->smart-open>=1.7.0->gensim)\n"
     ]
    }
   ],
   "source": [
    "!py3_env/bin/pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(4 unique tokens: ['check', 'chick', 'detection', 'sound'])\n",
      "[[(0, 1), (1, 1), (2, 2), (3, 1)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "print(dictionary)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.doc2bow?? # document to bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.251*\"detection\" + 0.250*\"check\" + 0.250*\"sound\"')\n",
      "(1, '0.359*\"detection\" + 0.214*\"chick\" + 0.214*\"sound\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "NUM_TOPICS = 2\n",
    "NUM_WORDS = 3\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = ldamodel.print_topics(num_words=NUM_WORDS)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загрузка аудиофайла из youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_dl in ./py3_env/lib/python3.6/site-packages\n",
      "Requirement already satisfied: oauth2client in ./py3_env/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six>=1.6.1 in ./py3_env/lib/python3.6/site-packages (from oauth2client)\n",
      "Requirement already satisfied: rsa>=3.1.4 in ./py3_env/lib/python3.6/site-packages (from oauth2client)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in ./py3_env/lib/python3.6/site-packages (from oauth2client)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in ./py3_env/lib/python3.6/site-packages (from oauth2client)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in ./py3_env/lib/python3.6/site-packages (from oauth2client)\n",
      "Collecting pydub\n",
      "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.23.1\n"
     ]
    }
   ],
   "source": [
    "!py3_env/bin/pip install youtube_dl\n",
    "!py3_env/bin/pip install oauth2client\n",
    "!py3_env/bin/pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] J5O5iRpLXKY: Downloading webpage\n",
      "[youtube] J5O5iRpLXKY: Downloading video info webpage\n",
      "[download] Destination: 1\n",
      "[download] 100% of 15.11MiB in 00:13.00KiB/s ETA 00:000\n",
      "[ffmpeg] Destination: wav\n",
      "Deleting original file 1 (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "import youtube_dl\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '192'\n",
    "    }],\n",
    "    'outtmpl': '1',\n",
    "    'prefer_ffmpeg': True,\n",
    "    'keepvideo': False\n",
    "}\n",
    "\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(['https://www.youtube.com/watch?v=J5O5iRpLXKY&t=637s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='data/3.wav'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "t1 = 110 * 1000 #Works in milliseconds\n",
    "t2 = 200 * 1000\n",
    "newAudio = AudioSegment.from_wav(\"data/1.wav\")\n",
    "newAudio = newAudio[t1:t2]\n",
    "newAudio.export('data/3.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'чтобы после очень крутой 18 года попробовать себя на западе А это произошло наверное летом летом 18 летом 18 года Так как только артист увидел офсет увидел эту ссылку Он резко отправил своим продюсером и сказал у меня переписку показывали потом эти же продюсер искал это моё секретное оружие Давайте звать парня и потихоньку очень медленно начинался запускается процесс То есть как бы это ни было моментально там о Попов и мы уже Я уже тут В начале обсуждал Ну поскольку у них стартовал тур совместно с дрейком не улавливает of цитата 11 чуваков из группы migos когда архитектуре это всегда любой клип запись альбома идёт очень медленно потому что они ежедневно просто путешествую фотосессии концерты в каждом городе по два по три концерта все солдаут были и наш тоже клип он сильно двигался медленно но ближе наверное в октябре уже нам Мне позвонили сказали всё Поехали Давай всё снимать придумывай идею У артиста из Кто такие заметную столько-то заметок что он хочет видеть и мы сейчас я с этим свой креативным директором креативный после Skype с креативным директором мы друг друга поняли я начинал писать сценарии отправлял ему постоянно разные обновление я написал 3 сценарий для них спустя месяц'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "with sr.AudioFile('data/3.wav') as source:\n",
    "    audio1 = recognizer.record(source)\n",
    "recognizer.recognize_google(audio1, language='ru_RU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse podcast topics with wor2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'й как нервничал тогда секс это правда что вы гений с юрий будет дуть дуть будет юрий очень стрёмно в'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/podcast.txt1', 'r+') as f:\n",
    "    text = f.read()\n",
    "text[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278\n",
      "745\n"
     ]
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "print(len(tokens))\n",
    "en_stop = set(nltk.corpus.stopwords.words('russian'))\n",
    "filtered_tokens = [token for token in tokens if token not in en_stop]\n",
    "print(len(filtered_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec([filtered_tokens], size=50, window=5, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ещё': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5c50>,\n",
       " 'это': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5e80>,\n",
       " 'очень': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5ef0>,\n",
       " 'время': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5e10>,\n",
       " 'украины': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5710>,\n",
       " 'россии': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5320>,\n",
       " 'поэтому': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5470>,\n",
       " 'хочу': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5390>,\n",
       " 'люди': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5080>,\n",
       " 'которые': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5160>,\n",
       " 'своей': <gensim.models.keyedvectors.Vocab at 0x7f14f86e50f0>,\n",
       " 'страны': <gensim.models.keyedvectors.Vocab at 0x7f14f86e52b0>,\n",
       " 'знаю': <gensim.models.keyedvectors.Vocab at 0x7f14f86e51d0>,\n",
       " 'людей': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5b00>,\n",
       " 'сама': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5240>,\n",
       " 'просто': <gensim.models.keyedvectors.Vocab at 0x7f14f86e54e0>,\n",
       " 'пропаганда': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5630>,\n",
       " 'думаю': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5be0>,\n",
       " 'сказали': <gensim.models.keyedvectors.Vocab at 0x7f14f86e55c0>,\n",
       " 'многие': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5550>,\n",
       " 'назвали': <gensim.models.keyedvectors.Vocab at 0x7f14f86e57f0>,\n",
       " 'жизнь': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5780>,\n",
       " 'фамилии': <gensim.models.keyedvectors.Vocab at 0x7f14f86e56a0>,\n",
       " 'называть': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5860>,\n",
       " 'кгб': <gensim.models.keyedvectors.Vocab at 0x7f14f86e58d0>,\n",
       " 'интервью': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5940>,\n",
       " 'страшно': <gensim.models.keyedvectors.Vocab at 0x7f14f86e59b0>,\n",
       " 'который': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5fd0>,\n",
       " 'дома': <gensim.models.keyedvectors.Vocab at 0x7f14f86e5f60>,\n",
       " 'говорю': <gensim.models.keyedvectors.Vocab at 0x7f14f83857b8>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = [model.wv[token] for token in filtered_tokens if token in model.wv.vocab]\n",
    "word_vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 36, 3: 24, 1: 35, 0: 16, 4: 33})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "clusters_counter = Counter(kmeans.predict(word_vectors))\n",
    "clusters_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC_1 люди сказали ещё своей сама\n",
      "TOPIC_2 очень думаю которые украины россии\n",
      "TOPIC_3 фамилии многие пропаганда людей кгб\n",
      "TOPIC_4 это ещё россии фамилии назвали\n",
      "TOPIC_5 хочу который страшно сказали люди\n"
     ]
    }
   ],
   "source": [
    "for i, cluster in enumerate(sorted(clusters_counter, \n",
    "                                   key=lambda cluster: clusters_counter[cluster], reverse=True)):\n",
    "    cluster_vector = kmeans.cluster_centers_[cluster]\n",
    "    topic = model.wv.similar_by_vector(cluster_vector, topn=5, restrict_vocab=None)\n",
    "    print('TOPIC_' + str(i+1), *[word[0] for word in topic])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
